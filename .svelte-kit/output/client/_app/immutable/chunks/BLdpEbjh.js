const n="atlas-labs",r="Atlas Labs System",a="A design-engineering operating system enabling rapid experimentation across a global innovation team.",l="2023",c="Enterprise",u=["Design System","Tooling","Accessibility"],d={headline:"A design system built to fuel weekly product launches.",subheadline:"Mk.01 partnered with Atlas Labs to craft a robust, accessible component library that unifies designers and engineers across six time zones."},m=["Component adoption across 12 product squads in three months.","60% reduction in handoff QA time.","Introduced accessibility governance resulting in WCAG 2.1 AA compliance."],g=[{id:"discovery",title:"Discovery & Inventory",description:"Facilitated cross-team audits, taxonomy workshops, and measurement frameworks to align goals."},{id:"system",title:"System Architecture",description:"Implemented token-driven architecture with theorem docs, Figma libraries, and storybook coverage."},{id:"scale",title:"Scaling & Enablement",description:"Hosted enablement sessions, built governance dashboards, and shipped automation to flag regressions."}],pe={slug:n,title:r,summary:a,year:l,industry:c,tags:u,hero:d,outcomes:m,chapters:g},he=Object.freeze(Object.defineProperty({__proto__:null,chapters:g,default:pe,hero:d,industry:c,outcomes:m,slug:n,summary:a,tags:u,title:r,year:l},Symbol.toStringTag,{value:"Module"})),p="flowstate",h="Flowstate Mindful Productivity",y="A mindful productivity platform using biometric feedback to adapt motion, focus, and ritual guidance.",b="2024",f="Health & Wellness",v=["Product Design","Mobile","Animation"],_={headline:"Crafting calming productivity with adaptive motion cues.",subheadline:"Flowstate blends biofeedback, motion design, and ritual planning into a beautifully immersive product."},k=["Daily active usage increased by 46% post-launch.","App Store rating climbed to 4.9 with 10k+ reviews.","Motion language adopted by internal design system guidelines."],j=[{id:"research",title:"Research & Synthesis",description:"Interviewed neuroscientists and focus coaches to translate rituals into interactive patterns."},{id:"motion",title:"Motion Language",description:"Defined easing, rhythm, and choreography aligned to heart rate variability and breathing cycles."},{id:"delivery",title:"Delivery",description:"Built Svelte Native prototypes, automated QA with Playwright, and orchestrated launch comms."}],ye={slug:p,title:h,summary:y,year:b,industry:f,tags:v,hero:_,outcomes:k,chapters:j},be=Object.freeze(Object.defineProperty({__proto__:null,chapters:j,default:ye,hero:_,industry:f,outcomes:k,slug:p,summary:y,tags:v,title:h,year:b},Symbol.toStringTag,{value:"Module"})),$="neon-metropolis",S="Neon Metropolis Launchverse",w="Immersive launch experience blending WebGL atmospherics with interactive storytelling chapters.",A="2024",x="Entertainment",O=["WebGL","Motion","Narrative UX"],P={headline:"A futuristic cityscape that responds to every interaction.",subheadline:"Mk.01 crafted the reveal for the Neon Metropolis platform, turning the browser into an experiential stage.",video:"/video/neon-metropolis-teaser.mp4"},M=["Launch day retention +38% compared to prior releases.","Global press coverage from 15 media outlets.","High net promoter score (92) from launch attendees."],T=[{id:"strategy",title:"Strategy & Narrative Blueprint",description:"We mapped the city districts to user funnels, aligning each to a storytelling beat and key business metric."},{id:"experience",title:"Experience Design",description:"Procedural skyline built with Three.js, volumetric shaders, and reactive audio; scroll timeline orchestrated via GSAP."},{id:"delivery",title:"Delivery & Optimization",description:"Implemented intelligent asset streaming, edge caching, and progressive loading cues reaching 92 Lighthouse performance."}],fe={slug:$,title:S,summary:w,year:A,industry:x,tags:O,hero:P,outcomes:M,chapters:T},ve=Object.freeze(Object.defineProperty({__proto__:null,chapters:T,default:fe,hero:P,industry:x,outcomes:M,slug:$,summary:w,tags:O,title:S,year:A},Symbol.toStringTag,{value:"Module"})),G="flicker-field",I="Flicker Field",L="Neural style transfer filmic pipeline bringing AI art direction to product launches.",W=["TensorFlow.js","WebGL","ffmpeg.wasm"],C="archived",D={demo:"https://mk1.dev/experiments/flicker-field",source:"https://github.com/your-handle/flicker-field"},_e={slug:G,title:I,summary:L,tech:W,status:C,links:D},ke=Object.freeze(Object.defineProperty({__proto__:null,default:_e,links:D,slug:G,status:C,summary:L,tech:W,title:I},Symbol.toStringTag,{value:"Module"})),z="glyph-suite",F="Glyph Suite",q="Parametric typography generator mapping sound and cursor input into responsive logomarks.",N=["Canvas API","Tone.js","Web Workers"],E="production",R={demo:"https://mk1.dev/experiments/glyph-suite",source:"https://github.com/your-handle/glyph-suite"},je={slug:z,title:F,summary:q,tech:N,status:E,links:R},$e=Object.freeze(Object.defineProperty({__proto__:null,default:je,links:R,slug:z,status:E,summary:q,tech:N,title:F},Symbol.toStringTag,{value:"Module"})),H="holo-cascade",Q="Holo Cascade",B="Volumetric hero system combining shader-driven atmospherics with scroll choreography.",U=["SvelteKit","GLSL","GSAP"],K="prototype",V={demo:"https://mk1.dev/experiments/holo-cascade",source:"https://github.com/your-handle/holo-cascade"},Se={slug:H,title:Q,summary:B,tech:U,status:K,links:V},we=Object.freeze(Object.defineProperty({__proto__:null,default:Se,links:V,slug:H,status:K,summary:B,tech:U,title:Q},Symbol.toStringTag,{value:"Module"})),Y="quantum-docs",X="Quantum Docs",J="Living documentation platform with AI-assisted examples and interactive sandboxes.",Z=["OpenAI API","mdsvex","Cloudflare Workers"],ee="production",te={demo:"https://mk1.dev/experiments/quantum-docs",source:"https://github.com/your-handle/quantum-docs"},Ae={slug:Y,title:X,summary:J,tech:Z,status:ee,links:te},xe=Object.freeze(Object.defineProperty({__proto__:null,default:Ae,links:te,slug:Y,status:ee,summary:J,tech:Z,title:X},Symbol.toStringTag,{value:"Module"})),se="sense-grid",oe="Sense Grid",ie="Collaborative story tapestry blending CRDTs with fluid motion systems.",ne=["Yjs","WebRTC","Svelte"],re="prototype",ae={demo:"https://mk1.dev/experiments/sense-grid",source:"https://github.com/your-handle/sense-grid"},Oe={slug:se,title:oe,summary:ie,tech:ne,status:re,links:ae},Pe=Object.freeze(Object.defineProperty({__proto__:null,default:Oe,links:ae,slug:se,status:re,summary:ie,tech:ne,title:oe},Symbol.toStringTag,{value:"Module"})),le="sonic-orbit",ce="Sonic Orbit",ue="Audio-reactive particle system that translates soundscapes into orbital choreography.",de=["Three.js","WebAudio API","GPU Instancing"],me="prototype",ge={demo:"https://mk1.dev/experiments/sonic-orbit",source:"https://github.com/your-handle/sonic-orbit"},Me={slug:le,title:ce,summary:ue,tech:de,status:me,links:ge},Te=Object.freeze(Object.defineProperty({__proto__:null,default:Me,links:ge,slug:le,status:me,summary:ue,tech:de,title:ce},Symbol.toStringTag,{value:"Module"})),Ge=Object.assign({"./projects/atlas-labs.json":he,"./projects/flowstate.json":be,"./projects/neon-metropolis.json":ve}),Ie=Object.assign({"./experiments/flicker-field.json":ke,"./experiments/glyph-suite.json":$e,"./experiments/holo-cascade.json":we,"./experiments/quantum-docs.json":xe,"./experiments/sense-grid.json":Pe,"./experiments/sonic-orbit.json":Te});function Le(t){const s=Object.entries(Ge).find(([i])=>i.includes(`${t}.json`));if(!s)return console.warn(`No project content found for ${t}`),null;const[,o]=s;return o.default}function e(t){const s=Object.entries(Ie).find(([i])=>i.includes(`${t}.json`));if(!s)return console.warn(`No experiment content found for ${t}`),null;const[,o]=s;return o.default}const We=[{slug:"sonic-orbit",title:"Sonic Orbit",summary:"Audio-reactive particle choreography rendered via instanced WebGL.",status:"prototype",thumbnail:"/images/labs/sonic-orbit.jpg",tech:["Three.js","WebAudio API","GPU Instancing"],highlight:"Transforms ambient soundscapes into orbital constellations.",links:e("sonic-orbit")?.links??{}},{slug:"holo-cascade",title:"Holo Cascade",summary:"Volumetric hero system combining shader-driven atmospherics with scroll control.",status:"prototype",thumbnail:"/images/labs/holo-cascade.jpg",tech:["SvelteKit","GLSL","GSAP"],highlight:"Breathes life into hero sections with liquid light transitions.",links:e("holo-cascade")?.links??{}},{slug:"glyph-suite",title:"Glyph Suite",summary:"Parametric typography generator mapping sound + cursor data into living wordmarks.",status:"production",thumbnail:"/images/labs/glyph-suite.jpg",tech:["Canvas API","Tone.js","Workers"],highlight:"Ships as a micro-SaaS companion for creative teams.",links:e("glyph-suite")?.links??{}},{slug:"sense-grid",title:"Sense Grid",summary:"Multiplayer grid narrative using CRDTs for collaborative story weaving.",status:"prototype",thumbnail:"/images/labs/sense-grid.jpg",tech:["Yjs","WebRTC","Svelte"],highlight:"Explores real-time narrative engines inside the browser.",links:e("sense-grid")?.links??{}},{slug:"quantum-docs",title:"Quantum Docs",summary:"Documentation engine with AI-assisted examples and interactive sandboxes.",status:"production",thumbnail:"/images/labs/quantum-docs.jpg",tech:["OpenAI API","mdsvex","Cloudflare Workers"],highlight:"Currently powers internal handbooks and public case studies.",links:e("quantum-docs")?.links??{}},{slug:"flicker-field",title:"Flicker Field",summary:"Neural style transfer applied to video textures for art-driven storytelling.",status:"archived",thumbnail:"/images/labs/flicker-field.jpg",tech:["TensorFlow.js","WebGL","ffmpeg.wasm"],highlight:"Archived after shipping learnings into client R&D projects.",links:e("flicker-field")?.links??{}}];export{Le as a,e as g,We as l};
